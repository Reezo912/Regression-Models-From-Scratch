# Mi Propia RegresiÃ³n Lineal y LogÃ­stica

Este proyecto implementa algoritmos de **RegresiÃ³n Lineal** y **RegresiÃ³n LogÃ­stica** desde cero usando NumPy. El objetivo es entender los conceptos fundamentales detrÃ¡s de estos algoritmos bÃ¡sicos de machine learning construyÃ©ndolos manualmente.

## ğŸ¯ DescripciÃ³n del Proyecto

Ambas implementaciones estÃ¡n diseÃ±adas para ser educativas y demuestran:
- **Fundamentos matemÃ¡ticos** de los algoritmos de regresiÃ³n
- **OptimizaciÃ³n por descenso de gradiente**
- **CÃ¡lculos de funciones de pÃ©rdida**
- **ComparaciÃ³n de rendimiento** con implementaciones de scikit-learn

## ğŸ“ Estructura del Proyecto

```
MyOwnLinearRegression/
â”œâ”€â”€ README.md
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ LinearRegression.py      # ImplementaciÃ³n de RegresiÃ³n Lineal
â”‚   â””â”€â”€ LogisticRegression.py    # ImplementaciÃ³n de RegresiÃ³n LogÃ­stica
â””â”€â”€ tests/
    â”œâ”€â”€ test_linear.py           # Prueba para regresiÃ³n lineal
    â””â”€â”€ test_logistic.py         # Prueba para regresiÃ³n logÃ­stica
```

## ğŸš€ CaracterÃ­sticas

### RegresiÃ³n Lineal
- **RegresiÃ³n lineal multivariante** implementada
- **FunciÃ³n de pÃ©rdida Error CuadrÃ¡tico Medio (MSE)**
- **OptimizaciÃ³n por descenso de gradiente**
- **Pruebas con dataset California Housing**
- **ComparaciÃ³n de rendimiento** con scikit-learn

### RegresiÃ³n LogÃ­stica
- **ClasificaciÃ³n binaria** implementada
- **FunciÃ³n de activaciÃ³n sigmoidea**
- **OptimizaciÃ³n de pÃ©rdida logarÃ­tmica (cross-entropy)**
- **Pruebas con dataset Breast Cancer**
- **EvaluaciÃ³n de mÃ©tricas de clasificaciÃ³n**

## ğŸ“¦ InstalaciÃ³n

1. Clona el repositorio:
```bash
git clone <url-del-repositorio>
cd MyOwnLinearRegression
```

2. Instala las dependencias:
```bash
pip install -r requirements.txt
```

## ğŸ”§ Uso

### RegresiÃ³n Lineal

```python
from src.LinearRegression import LinearRegression
from sklearn.datasets import fetch_california_housing

# Cargar y preparar datos
data = fetch_california_housing()
X, y = data.data, data.target

# Crear y entrenar modelo
model = LinearRegression(epoch=1000, lr=0.001)
model.fit(X_train, y_train)

# Hacer predicciones
predictions = model.predict(X_test)
```

### RegresiÃ³n LogÃ­stica

```python
from src.LogisticRegression import LogisticRegression
from sklearn.datasets import load_breast_cancer

# Cargar y preparar datos
data = load_breast_cancer()
X, y = data.data, data.target

# Crear y entrenar modelo
model = LogisticRegression(epoch=10000, lr=0.0001)
model.fit(X_train, y_train)

# Hacer predicciones
predictions = model.predict(X_test)
probabilities = model.predict_proba(X_test)
```

## ğŸ§ª Pruebas

Ejecuta los scripts de prueba para comparar tus implementaciones con scikit-learn:

```bash
python tests/test_linear.py
python tests/test_logistic.py
```

Esto mostrarÃ¡ las mÃ©tricas de rendimiento tanto para tu implementaciÃ³n como para la versiÃ³n de scikit-learn.

## ğŸ“Š Resultados

### RegresiÃ³n Lineal
- **Dataset**: California Housing
- **CaracterÃ­sticas**: 8 caracterÃ­sticas numÃ©ricas
- **Objetivo**: Valor mediano de la casa
- **Rendimiento**: Comparable a la implementaciÃ³n de scikit-learn

### RegresiÃ³n LogÃ­stica
- **Dataset**: Breast Cancer Wisconsin
- **CaracterÃ­sticas**: 30 caracterÃ­sticas numÃ©ricas
- **Objetivo**: ClasificaciÃ³n binaria (maligno/benigno)
- **MÃ©tricas**: Accuracy, Precision, Recall, F1-Score

## ğŸ§® Antecedentes MatemÃ¡ticos

### RegresiÃ³n Lineal
- **HipÃ³tesis**: `y = X @ w + b`
- **FunciÃ³n de PÃ©rdida**: `MSE = (1/n) * Î£(y_true - y_pred)Â²`
- **Descenso de Gradiente**: Actualiza pesos usando derivadas parciales

### RegresiÃ³n LogÃ­stica
- **HipÃ³tesis**: `y = sigmoid(X @ w + b)`
- **ActivaciÃ³n**: `sigmoid(z) = 1/(1 + e^(-z))`
- **FunciÃ³n de PÃ©rdida**: `Log Loss = -Î£(y_true * log(y_pred) + (1-y_true) * log(1-y_pred))`

## ğŸ› ï¸ Dependencias

- `numpy`: CÃ¡lculos numÃ©ricos
- `scikit-learn`: Carga de datasets y comparaciÃ³n

## ğŸ“š Recursos de Aprendizaje

Este proyecto fue inspirado por:
- **Mathematics for Machine Learning** de Marc Peter Deisenroth y Aldo Faisal
- **Curso "Mathematics for Machine Learning" del Imperial College London en Coursera**
- **DocumentaciÃ³n de Scikit-learn** para comparaciÃ³n de implementaciones

## ğŸ¤ Contribuciones

SiÃ©ntete libre de contribuir:
- Agregando nuevas caracterÃ­sticas
- Mejorando la documentaciÃ³n
- Optimizando algoritmos
- Agregando mÃ¡s casos de prueba

## ğŸ“„ Licencia

Este proyecto es de cÃ³digo abierto y estÃ¡ disponible bajo la Licencia MIT.

---

**Nota**: Este proyecto es principalmente educativo. Para uso en producciÃ³n, considera usar bibliotecas establecidas como scikit-learn, TensorFlow, o PyTorch.