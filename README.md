
# Mi Propia RegresiÃ³n Lineal y LogÃ­stica

[![MIT License](https://img.shields.io/badge/license-MIT-blue.svg)](LICENSE)
[![Python Version](https://img.shields.io/badge/python-3.8%2B-green)](https://www.python.org/downloads/)

Este proyecto implementa algoritmos de **RegresiÃ³n Lineal** y **RegresiÃ³n LogÃ­stica** desde cero utilizando NumPy, con el objetivo de entender los conceptos fundamentales detrÃ¡s de estos mÃ©todos bÃ¡sicos de Machine Learning.

## ğŸ¯ DescripciÃ³n del Proyecto

Ambas implementaciones buscan ser educativas, demostrando:
- Fundamentos matemÃ¡ticos claros.
- OptimizaciÃ³n mediante descenso de gradiente.
- Funciones de pÃ©rdida y mÃ©tricas de evaluaciÃ³n.
- ComparaciÃ³n directa con implementaciones de scikit-learn.

## ğŸ“ Estructura del Proyecto

```
MyOwnLinearRegression/
â”œâ”€â”€ README.md
â”œâ”€â”€ LICENSE
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ LinearRegression.py      # ImplementaciÃ³n desde cero de RegresiÃ³n Lineal
â”‚   â””â”€â”€ LogisticRegression.py    # ImplementaciÃ³n desde cero de RegresiÃ³n LogÃ­stica
â””â”€â”€ tests/
    â”œâ”€â”€ test_linear.py           # Pruebas para regresiÃ³n lineal
    â””â”€â”€ test_logistic.py         # Pruebas para regresiÃ³n logÃ­stica
```

## ğŸš€ CaracterÃ­sticas

### RegresiÃ³n Lineal
- RegresiÃ³n lineal multivariante.
- FunciÃ³n de pÃ©rdida: Error CuadrÃ¡tico Medio (MSE).
- OptimizaciÃ³n mediante descenso de gradiente.
- Validado con el dataset **California Housing**.

### RegresiÃ³n LogÃ­stica
- ClasificaciÃ³n binaria.
- FunciÃ³n de activaciÃ³n: Sigmoide.
- FunciÃ³n de pÃ©rdida: Log Loss (Cross-Entropy).
- Validado con el dataset **Breast Cancer Wisconsin**.

## ğŸ“¦ InstalaciÃ³n

Clona el repositorio:
```bash
git clone https://github.com/Reezo912/Regression-Models-From-Scratch
cd Regression-Models-From-Scratch
```

Instala dependencias:
```bash
pip install -r requirements.txt
```


## ğŸ§ª Pruebas

Ejecuta scripts para comparar los modelos con scikit-learn:

```bash
python tests/test_linear.py
python tests/test_logistic.py
```

Resultados ejemplo:

```
=== SKLEARN (Logistic) ===
Accuracy: 0.9860
F1 Score: 0.9888

=== MI MODELO (Logistic) ===
Accuracy: 0.9790
F1 Score: 0.9832
```

## ğŸ“Š Resultados Obtenidos

### RegresiÃ³n Lineal (California Housing)
- **MSE** en conjunto de prueba comparable a scikit-learn.

### RegresiÃ³n LogÃ­stica (Breast Cancer Wisconsin)
- **Accuracy** superior al 97%.
- **Precision**, **Recall** y **F1-Score** similares a scikit-learn.

## ğŸ§® Fundamentos MatemÃ¡ticos

| Modelo              | HipÃ³tesis                                                                                                                                     | FunciÃ³n de PÃ©rdida                                                                                                                 |
|---------------------|-----------------------------------------------------------------------------------------------------------------------------------------------|-------------------------------------------------------------------------------------------------------------------------------------|
| RegresiÃ³n Lineal    | ![LinearHypothesis](https://latex.codecogs.com/png.image?\dpi{110}\bg{white}y=Xw+b)                                                          | ![MSE](https://latex.codecogs.com/png.image?\dpi{110}\bg{white}MSE=\frac{1}{n}\sum\left(y-\hat{y}\right)^{2})                     |
| RegresiÃ³n LogÃ­stica | ![LogisticHypothesis](https://latex.codecogs.com/png.image?\dpi{110}\bg{white}y=sigmoid(Xw+b))                                               | ![LogLoss](https://latex.codecogs.com/png.image?\dpi{110}\bg{white}LogLoss=-\frac{1}{n}\sum\left[y\log(\hat{y})+(1-y)\log(1-\hat{y})\right]) |


- **Descenso de Gradiente:** ActualizaciÃ³n iterativa usando derivadas parciales.

## ğŸ› ï¸ Dependencias
- `numpy`: CÃ¡lculos numÃ©ricos.
- `scikit-learn`: Datasets y comparaciÃ³n.

Instala todas con `pip install -r requirements.txt`.

## ğŸ”§ SoluciÃ³n de Problemas

### Error: "ModuleNotFoundError"
```bash
pip install -r requirements.txt
```

### Error: "ImportError"
AsegÃºrate de estar en el directorio raÃ­z del proyecto.

### Error: "ValueError: Found input variables with inconsistent numbers of samples"
Verifica que X_train y y_train tengan el mismo nÃºmero de muestras.

### Error: "ConvergenceWarning"
Aumenta el nÃºmero de epochs o ajusta el learning rate.

## ğŸ“š Referencias y Recursos
- Libro: **Mathematics for Machine Learning** (Deisenroth & Faisal)
- Curso: **Mathematics for Machine Learning** (Imperial College London - Coursera)
- DocumentaciÃ³n oficial de [scikit-learn](https://scikit-learn.org/stable/)

## ğŸš€ Roadmap

### PrÃ³ximas CaracterÃ­sticas
- [ ] ImplementaciÃ³n de RegularizaciÃ³n (Ridge/Lasso)
- [ ] RegresiÃ³n LogÃ­stica Multiclase
- [ ] ValidaciÃ³n Cruzada
- [ ] Visualizaciones de resultados
- [ ] Optimizadores alternativos (Adam, SGD)

### Mejoras TÃ©cnicas
- [ ] ParalelizaciÃ³n del entrenamiento
- [ ] Early stopping
- [ ] Learning rate scheduling
- [ ] Batch gradient descent

## ğŸ¤ CÃ³mo Contribuir
Â¡Tu contribuciÃ³n es bienvenida!
- Abre un Issue con mejoras.
- EnvÃ­a un Pull Request.
- Mejora documentaciÃ³n y agrega ejemplos.

## ğŸ“„ Licencia
[MIT](LICENSE)

---

**Nota Final:** Este proyecto es educativo. Para producciÃ³n utiliza librerÃ­as profesionales como **scikit-learn**, **TensorFlow**, o **PyTorch**.
